#!/usr/bin/env python3
"""
TorFileDownloader í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
.onion ë§í¬ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import asyncio
import logging
from pathlib import Path
from web_crawler import WebCrawler
from tor_file_downloader import TorFileDownloader

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_tor_file_downloader():
    """TorFileDownloader ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§… TorFileDownloader ê¸°ë³¸ í…ŒìŠ¤íŠ¸...")
    
    try:
        # TorFileDownloader ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        downloader = TorFileDownloader(
            use_tor=True,
            tor_port=9051,
            max_retries=3
        )
        
        print("âœ… TorFileDownloader ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
        
        # í…ŒìŠ¤íŠ¸ìš© ì¼ë°˜ URL (Tor ì—†ì´ë„ ì‘ë™ í™•ì¸)
        test_url = "http://dwkcmg5ewqvmuacunudjr7so5l2jq7wneafdzsnjllmbcec3nwu7o7id.onion/softwares/1/downloads/2"
        test_dir = "./test_downloads"
        
        # ë””ë ‰í„°ë¦¬ ìƒì„±
        Path(test_dir).mkdir(exist_ok=True)
        
        print(f"ğŸ“¥ í…ŒìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ: {test_url}")
        
        # íŒŒì¼ ë‹¤ìš´ë¡œë“œ í…ŒìŠ¤íŠ¸
        result = downloader.download_file(
            url=test_url,
            target_dir=test_dir,
            filename="Fileis_setup.exe"
        )
        
        if result:
            print(f"âœ… ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {result}")
            
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if Path(result).exists():
                file_size = Path(result).stat().st_size
                print(f"ğŸ“ íŒŒì¼ í¬ê¸°: {file_size} bytes")
            else:
                print("âŒ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        else:
            print("âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        logger.error(f"TorFileDownloader í…ŒìŠ¤íŠ¸ ì—ëŸ¬: {e}")


async def test_web_crawler_with_tor():
    """WebCrawlerì˜ Tor í†µí•© í…ŒìŠ¤íŠ¸"""
    print("\nğŸ•·ï¸ WebCrawler Tor í†µí•© í…ŒìŠ¤íŠ¸...")
    
    try:
        # Tor í™œì„±í™”ëœ ì„¤ì •
        config = {
            'use_tor': True,
            'tor_port': 9051,
            'download_dir': './test_downloads_tor',
            'max_crawl_depth': 1,
            'file_types': ['documents', 'images'],
            'enable_logging': True,
            'log_level': 'INFO'
        }
        
        # WebCrawler ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        crawler = WebCrawler(config)
        print("âœ… Tor í™œì„±í™”ëœ WebCrawler ìƒì„± ì„±ê³µ")
        
        # ì¼ë°˜ ì›¹ì‚¬ì´íŠ¸ í…ŒìŠ¤íŠ¸ (Tor í†µí•´ì„œ)
        test_urls = ["http://dwkcmg5ewqvmuacunudjr7so5l2jq7wneafdzsnjllmbcec3nwu7o7id.onion"]
        
        print(f"ğŸ” í¬ë¡¤ë§ ì‹œì‘: {test_urls}")
        
        # íŒŒì¼ ë§í¬ë§Œ ì°¾ê¸° í…ŒìŠ¤íŠ¸
        file_links = await crawler.find_files_only(
            urls=test_urls,
            file_types=['documents', 'images']
        )
        
        print("ğŸ“‹ ë°œê²¬ëœ íŒŒì¼ ë§í¬:")
        for file_type, links in file_links.items():
            if links:
                print(f"  {file_type}: {len(links)}ê°œ")
                for link in links[:3]:  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥
                    print(f"    - {link}")
        
        if any(file_links.values()):
            print("\nğŸ“¥ íŒŒì¼ ë‹¤ìš´ë¡œë“œ í…ŒìŠ¤íŠ¸...")
            result = await crawler.crawl_and_download(
                urls=test_urls,
                file_types=['documents', 'images'],
                output_dir='./test_downloads_tor'
            )
            
            print("ğŸ“Š ë‹¤ìš´ë¡œë“œ ê²°ê³¼:")
            print(f"  ì„±ê³µ: {result['stats']['files_downloaded']}ê°œ")
            print(f"  ì‹¤íŒ¨: {len(result['stats']['errors'])}ê°œ")
            
        else:
            print("ğŸ“ ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            
    except Exception as e:
        print(f"âŒ WebCrawler í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        logger.error(f"WebCrawler Tor í…ŒìŠ¤íŠ¸ ì—ëŸ¬: {e}")


def test_onion_link_detection():
    """onion ë§í¬ ê°ì§€ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§… .onion ë§í¬ ê°ì§€ í…ŒìŠ¤íŠ¸...")
    
    from link_detector import LinkDetector
    
    detector = LinkDetector(use_tor=True)
    
    test_urls = [
        #"http://dwkcmg5ewqvmuacunudjr7so5l2jq7wneafdzsnjllmbcec3nwu7o7id.onion"
        "http://dwkcmg5ewqvmuacunudjr7so5l2jq7wneafdzsnjllmbcec3nwu7o7id.onion"
    ]
    
    print("ğŸ” URL í…ŒìŠ¤íŠ¸:")
    for url in test_urls:
        is_onion = detector.is_onion_url(url)
        status = "ğŸ§… .onion" if is_onion else "ğŸŒ ì¼ë°˜"
        print(f"  {status}: {url}")


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸš€ TorFileDownloader í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # 1. onion ë§í¬ ê°ì§€ í…ŒìŠ¤íŠ¸
    test_onion_link_detection()
    
    # 2. TorFileDownloader ê¸°ë³¸ í…ŒìŠ¤íŠ¸
    #test_tor_file_downloader()
    
    # 3. WebCrawler Tor í†µí•© í…ŒìŠ¤íŠ¸
    asyncio.run(test_web_crawler_with_tor())
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("\nğŸ“ ì£¼ì˜ì‚¬í•­:")
    print("- .onion ë§í¬ ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•´ì„œëŠ” Tor ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤")
    print("- Tor Browser ë˜ëŠ” ë³„ë„ Tor ë°ëª¬ì´ í¬íŠ¸ 9051ì—ì„œ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•©ë‹ˆë‹¤")
    print("- ì‹¤ì œ .onion ì‚¬ì´íŠ¸ í…ŒìŠ¤íŠ¸ëŠ” í•´ë‹¹ ì‚¬ì´íŠ¸ê°€ ì ‘ê·¼ ê°€ëŠ¥í•  ë•Œë§Œ ì‘ë™í•©ë‹ˆë‹¤")


if __name__ == "__main__":
    main()